---
title: 核心概念
nav_order: 1
parent: 核心概念篇
---

# 第 0 章：核心概念 (Core Concepts)

## LLM（大语言模型）

ChatGPT、Claude、Gemini、DeepSeek 等都是 LLM。本质是**超大号的"文字接龙"机器**——给一段文字，按概率逐词预测下一个词。当参数量达到千亿级别，它就能写代码、写文章、做数学题。

> LLM = 一个读过所有书的文字接龙冠军。

## LLM API（大模型接口）

LLM 跑在云端 GPU 集群上，厂商通过 HTTP API 提供调用能力：

```
你的代码 → HTTP POST（带上问题） → LLM 服务 → HTTP 响应（返回回答）
```

跟调微信支付、高德地图接口没有本质区别。本项目支持 **Gemini**、**DeepSeek**、**智谱**、**腾讯混元** 等多家模型 API。

> LLM API = 给 AI 打电话的号码。

## Context（上下文）

LLM 本身是**无状态**的——每次调用都是一次全新的请求，它不会记得上一句你说了什么。所谓"上下文"，就是你随请求一起发过去的**所有信息**，包括：

- **对话历史**：之前的每一轮问答
- **系统提示词**：告诉 AI "你是谁、该怎么做"的指令
- **工具结果**：上一步工具调用返回的数据

```
第 1 次请求：[消息1]                          → AI 回复1
第 2 次请求：[消息1, 回复1, 消息2]             → AI 回复2
第 3 次请求：[消息1, 回复1, 消息2, 回复2, 消息3] → AI 回复3
```

每次都把完整历史发过去，AI 才能"记住"之前聊了什么。**"记忆"不在 AI 脑子里，而在你发送的数组里。**

每个模型有**上下文窗口**（Context Window）限制，比如 128K tokens。超出这个长度，最早的内容就会被截掉。就像一块有限大小的白板，写满了只能擦掉最早的内容。

> 上下文 = 每次打电话时，先把之前的聊天记录从头念一遍。

## Tool / Function Calling（工具调用）

这是从"聊天机器人"进化到"Agent"的关键。普通 LLM 只能生成文字，问它天气只能瞎编。但如果告诉它有个 `get_weather` 工具，它会返回：

```json
{ "functionCall": { "name": "get_weather", "args": { "city": "深圳" } } }
```

**LLM 并没有真的查天气**，它只是说"我想调这个工具"。真正执行的是你的代码。

> Tool = AI 的手脚。LLM 负责"动脑"决策，代码负责"动手"执行。

## AI Agent（智能体）

Agent 是一种**架构模式**，把上面三者串在一起：

```
Agent = LLM（大脑） + Tools（手脚） + Loop（驱动循环）
```

1. **LLM** 负责理解任务、做出决策
2. **Tools** 负责执行具体操作
3. **Loop** 让 AI 反复"思考→行动→观察"，直到任务完成

> AI Agent = 一个被放进循环里的 LLM，每一圈可以选择"说话"或"用工具"，直到搞定任务。

## MCP（Model Context Protocol）

有了 Tool Calling，Agent 可以调用工具。但每接一个新工具，你都要写一套定义、解析、执行的代码。工具一多，就像每个电器都用不同的插头——混乱且难以维护。

**MCP（模型上下文协议）** 就是 AI 世界的 **USB 接口标准**。它定义了一套统一的协议，让 Agent 能以即插即用的方式对接外部工具和数据源：

```
┌──────────┐     MCP 协议     ┌──────────┐     MCP 协议     ┌──────────┐
│  Agent   │ ◀──(标准接口)──▶ │MCP Client│ ◀──(标准接口)──▶ │MCP Server│
│ (Host)   │                  │          │                  │(工具提供方)│
└──────────┘                  └──────────┘                  └──────────┘
```

工具提供方只需实现一个 MCP Server，任何支持 MCP 的 Agent 就能直接使用，无需定制开发。

> MCP = AI 工具的 USB 接口。插上就能用，不用管内部怎么实现。

## Sub-Agent（子智能体）

一个 Agent 什么都干，就像一个人又写代码、又做设计、又跑测试——容易出错，上下文也会被塞满无关信息。

**Sub-Agent** 模式是让主 Agent 把子任务**委派**给专门的小 Agent，就像团队里的 Tech Lead 把任务分给不同的工程师：

```
                    ┌─────────────┐
                    │  主 Agent    │
                    │ (Tech Lead) │
                    └──────┬──────┘
               ┌───────────┼───────────┐
               ▼           ▼           ▼
         ┌──────────┐ ┌──────────┐ ┌──────────┐
         │代码 Agent│ │搜索 Agent│ │测试 Agent│
         └──────────┘ └──────────┘ └──────────┘
```

每个子 Agent 有自己独立的上下文和专属工具，做完后只把结果交还给主 Agent。分工明确，互不干扰。

> Sub-Agent = 任务太大时，分给几个专才各干各的，最后汇总结果。

## Agent Skill（技能）

Tool 是单个动作（比如"读文件"），但很多任务是一套**固定流程**（比如"生成 Git commit"需要：查状态 → 看 diff → 写 commit message → 执行提交）。

**Agent Skill** 就是预定义好的 **prompt + 工具组合**，类似游戏里的"技能快捷键"——一键触发一整套流程：

```
用户输入 /commit
      │
      ▼
┌─────────────────────────────┐
│ Skill: commit               │
│  1. git status              │
│  2. git diff                │
│  3. 生成 commit message     │
│  4. git commit              │
└─────────────────────────────┘
```

Skill 和 Tool 的区别：**Tool 是一把螺丝刀，Skill 是一整套"拆机教程"。**

> Agent Skill = 一键触发的预置流程，把多个工具和 prompt 打包成快捷操作。

## Context Management（上下文管理）

前面说过，LLM 的上下文窗口是有限的。对话越长，历史消息越多，总会塞满。而且 token 越多，**响应越慢、费用越高**。

上下文管理就是在"记住足够多"和"别超标"之间找平衡。常见策略：

```
策略1：滑动窗口        只保留最近 N 轮对话，丢弃更早的
策略2：摘要压缩        用 LLM 把旧对话压缩成一段摘要
策略3：RAG 检索增强    需要时从外部知识库检索相关内容，按需注入上下文
```

这三种策略可以组合使用。比如：用滑动窗口保留近期对话，对更早的历史做摘要压缩，需要特定知识时用 RAG 检索。

> Context Management = 在有限的白板上，决定哪些内容要保留、哪些可以擦掉、哪些需要时再查。
